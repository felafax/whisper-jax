{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to restart the kernel for the setup stage to be applied**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/felafax/whisper-jax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./whisper-jax; pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets soundfile librosa numpy huggingface scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class ASRBenchmark:\n",
    "    def __init__(self, audio):\n",
    "        self.audio = audio\n",
    "        self.duration = len(audio['array']) / audio['sampling_rate']\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.end = time.time()\n",
    "        self.elapsed = self.end - self.start\n",
    "        rtf = self.duration / self.elapsed\n",
    "    \n",
    "        print(f\"  üéß  Audio Duration         ‚îÇ  {(self.duration/60):.2f} minutes\")\n",
    "        print(f\"  ‚è≥ Model Execution Time    ‚îÇ  {self.elapsed:.3f} seconds\")\n",
    "        print(f\"  üöÑ Real-Time Factor (RTF)  ‚îÇ  {rtf:.3f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper_jax import FlaxWhisperPipline\n",
    "import jax.numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FlaxWhisperPipline(\"openai/whisper-large-v2\", dtype=jnp.bfloat16, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then initialise a compilation cache, which will speed-up the compilation time if we close our kernel and want to compile the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "\n",
    "!rm -rf ./jax_cache\n",
    "cc.initialize_cache(\"./jax_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé∂ Loading audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "test_dataset = load_dataset(\"sanchit-gandhi/whisper-jax-test-files\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = test_dataset[1][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a listen to the audio file that we've loaded - we'll see that it's approximately 5 mins long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_30m = audio\n",
    "audio_10m = audio.copy()\n",
    "audio_10m['array'] = audio_30m['array'][:audio_30m['array'].shape[0] // 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(audio[\"array\"], rate=audio[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model - 10 Minute benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a JIT compilation warmup\n",
    "%time text = pipeline(audio_10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ASRBenchmark(audio_10m):\n",
    "    text = pipeline(audio_10m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 Minute run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = test_dataset[1][\"audio\"]  # load the second sample (30 mins) and get the audio array\n",
    "\n",
    "audio_length_in_mins = len(audio[\"array\"]) / audio[\"sampling_rate\"] / 60\n",
    "print(f\"Audio is {audio_length_in_mins} mins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time text = pipeline(audio_30m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ASRBenchmark(audio_30m):\n",
    "    text = pipeline(audio_30m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
